{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Pipeline for Feature Build and Load to Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "model_package_group_name = f\"FeatureStorePackage\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_fraud_bucket_name = 'demo-insurance-claims'\n",
    "file_key = 'claims_feature_store.csv'\n",
    "input_data_uri = 's3://{}/{}'.format(claim_fraud_bucket_name, file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "storage_instance_type = ParameterString(\n",
    "    name=\"FeatureStoreInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the processing script\n",
    "\n",
    "Four steps to create the Feature Processing step in the Pipeline:\n",
    "\n",
    "* We define the features as functions in the file : ```fs_job/Features.py```\n",
    "* We create an instance of SKLearnProcessor\n",
    "* Define a script to process an input file : ```fs_job/preprocessing.py```\n",
    "* We create a step in the Pipeline that executes the feature processing job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fs_job/Features.py\n",
    "\n",
    "\"\"\"\n",
    "This file defines your custom features.\n",
    "It will be used to populate a custom feature group.\n",
    "The contents of this file will be inspected to determine\n",
    "the number of features (number of functions).\n",
    "\n",
    "These functions need to be aware of the column names in the dataframe\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def InjuryToVehicleClaimRatio(df):\n",
    "    return df[\"injury_claim\"]/df[\"vehicle_claim\"]\n",
    "\n",
    "def ReportIsStrange(df):\n",
    "    regex = \"weird|strange|inconsistent|unusual|suspicious\"\n",
    "    return df[\"report\"].str.contains(regex, regex=True, case=False, na=False).map(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "claims_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-feature-process\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fs_job/preprocessing.py\n",
    "\n",
    "from inspect import getmembers, isfunction\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "  \n",
    "import sys\n",
    "src_path = \"/opt/ml/processing/src\"\n",
    "sys.path.append(src_path)\n",
    "\n",
    "sys.stderr.write(\"PATH UPDATED \")\n",
    "sys.stderr.write( str(sys.path) )\n",
    "\n",
    "files =  os.listdir(src_path)\n",
    "sys.stderr.write( str(files) )\n",
    "\n",
    "import Features as features\n",
    "\n",
    "funcs = getmembers(features, isfunction)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/claims_feature_store.csv\",\n",
    "    )\n",
    "    \n",
    "    for f in funcs:\n",
    "        feature_name = f[0]\n",
    "        function = f[1]\n",
    "        df[feature_name] = function(df)\n",
    "        \n",
    "    pd.DataFrame(df).to_csv(f\"{base_dir}/output/claims_feature_store.csv\", header=True, index=False)\n",
    "\n",
    "    sample = df.head()\n",
    "    \n",
    "    pd.DataFrame(sample).to_csv(f\"{base_dir}/sample/sample.csv\", header=True, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "features_file = \"fs_job/Features.py\"\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"ClaimsProcess\",\n",
    "    processor=claims_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"), \n",
    "      ProcessingInput(source=features_file, destination=\"/opt/ml/processing/src\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\"),\n",
    "        ProcessingOutput(output_name=\"sample\", source=\"/opt/ml/processing/sample\")\n",
    "    ],\n",
    "    code=\"fs_job/preprocessing.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Processing Job that Loads the results into the Feature Store\n",
    "\n",
    "A second processing job, that loads the results of the previous step into Sagemaker Feature Store as a predetermined Feature Group. The default behaviour is over-write any exisiting Feature Group of the same name.\n",
    "\n",
    "Note: We are having to install the sagemaker package to make this work. Ideally, you would create a custom image that has everything you need for this processing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fs_job/feature_store.py\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "install(\"sagemaker\")\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"eu-west-2\"\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sys.stderr.write( (\"ARN ROLE\" + role) )\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker-featurestore'\n",
    "offline_feature_store_bucket = 's3://{}/{}'.format(default_bucket, prefix)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")\n",
    "\n",
    "s3_client = boto_session.client(service_name='s3', region_name=region)\n",
    "\n",
    "src_path = \"/opt/ml/processing/src\"\n",
    "sys.path.append(src_path)\n",
    "\n",
    "sys.stderr.write( \"LISTING SRC DIR\" )\n",
    "files =  os.listdir(src_path)\n",
    "sys.stderr.write( str(files) )\n",
    "\n",
    "sys.stderr.write( \"LISTING DATA DIR\" )\n",
    "files =  os.listdir(\"/opt/ml/processing/data/\")\n",
    "sys.stderr.write( str(files) )\n",
    "\n",
    "import FeatureStoreUtils as fsu\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_file_path = \"/opt/ml/processing/data/claims_feature_store.csv\"\n",
    "    claims_data = pd.read_csv(data_file_path)\n",
    "    \n",
    "    # IDEALLY THESE WOULD BE PASSED AS PARAMETERS\n",
    "    feature_group_name = \"Claims-Features\"\n",
    "    feature_group_desc = \"Core Insurance Claims data for building various models\"\n",
    "    record_identifier_name = \"policy_id\"\n",
    "    event_time_feature_name = \"claim_date\"\n",
    "\n",
    "    fg = fsu.recreate_feature_store_from_dataframe(\n",
    "        df=claims_data, \n",
    "        role=role, \n",
    "        fs_session=feature_store_session, \n",
    "        sm_client=sagemaker_client, \n",
    "        fg_name=feature_group_name, \n",
    "        fg_descr=feature_group_desc, \n",
    "        record_col=record_identifier_name, \n",
    "        event_col=event_time_feature_name, \n",
    "        s3_uri=offline_feature_store_bucket\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"feature-store-process\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs_utils = \"fs_job/FeatureStoreUtils.py\"\n",
    "\n",
    "step_feature_store = ProcessingStep(\n",
    "    name=\"FeatureStoreStep\",\n",
    "    processor=fs_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=step_process.properties.ProcessingOutputConfig.Outputs[\"sample\"].S3Output.S3Uri, destination=\"/opt/ml/processing/sample\"), \n",
    "      ProcessingInput(source=step_process.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri, destination=\"/opt/ml/processing/data\"), \n",
    "      ProcessingInput(source=fs_utils, destination=\"/opt/ml/processing/src\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\")\n",
    "    ],\n",
    "    code=\"fs_job/feature_store.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"FeatureStorePipeline\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        processing_instance_type, \n",
    "        storage_instance_type,\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_process, step_feature_store],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:712779665605:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
